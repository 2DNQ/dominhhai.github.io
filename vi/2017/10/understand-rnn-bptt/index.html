<!doctype html><html lang=vi><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=generator content="Hugo 0.31.1 with theme Tranquilpeak 0.4.1-BETA"><title>[RNN] Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm</title><meta name=author content="Do Minh Hai"><meta name=keywords content="Mạng RNN,Học Sâu,Deep Learning,dominhhai,programming,computer science,machine learning,deep learning"><link rel=icon href=https://dominhhai.github.io/favicon/golden-buddha-512-79567.png><link rel=canonical href=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/><meta name=description content="Bài giới thiệu RNN thứ 3 này được dịch lại từ trang blog WILDML.


Trong phần này tôi sẽ giới thiệu tổng quan về BPTT (Backpropagation Through Time) và giải thích sự khác biệt của nó so với các giải thuật lan truyền ngược truyền thống.
Sau đó ta sẽ cùng tìm hiểu vấn đề mất mát đạo hàm (vanishing gradient problem), nó dẫn ta tới việc phát triển của LSTM và GRU - 2 mô hình phổ biến và mạnh mẽ nhất hiện nay trong các bài toán NLP (và cả các lĩnh vực khác)."><meta property=og:type content=website><meta property=og:title content="[RNN] Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm"><meta property=og:url content=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/><meta property=og:description content="Bài giới thiệu RNN thứ 3 này được dịch lại từ trang blog WILDML.


Trong phần này tôi sẽ giới thiệu tổng quan về BPTT (Backpropagation Through Time) và giải thích sự khác biệt của nó so với các giải thuật lan truyền ngược truyền thống.
Sau đó ta sẽ cùng tìm hiểu vấn đề mất mát đạo hàm (vanishing gradient problem), nó dẫn ta tới việc phát triển của LSTM và GRU - 2 mô hình phổ biến và mạnh mẽ nhất hiện nay trong các bài toán NLP (và cả các lĩnh vực khác)."><meta property=og:site_name content="Hai's Blog"><meta property=og:locale content=vi><meta name=twitter:card content=summary><meta name=twitter:title content="[RNN] Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm"><meta name=twitter:url content=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/><meta name=twitter:description content="Bài giới thiệu RNN thứ 3 này được dịch lại từ trang blog WILDML.


Trong phần này tôi sẽ giới thiệu tổng quan về BPTT (Backpropagation Through Time) và giải thích sự khác biệt của nó so với các giải thuật lan truyền ngược truyền thống.
Sau đó ta sẽ cùng tìm hiểu vấn đề mất mát đạo hàm (vanishing gradient problem), nó dẫn ta tới việc phát triển của LSTM và GRU - 2 mô hình phổ biến và mạnh mẽ nhất hiện nay trong các bài toán NLP (và cả các lĩnh vực khác)."><meta name=twitter:creator content=@minhhai3b><meta property=og:image content="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=640"><meta name=twitter:image content="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=640"><meta property=og:image content=https://res.cloudinary.com/dominhhai/image/upload/dl/logo.png><meta name=twitter:image content=https://res.cloudinary.com/dominhhai/image/upload/dl/logo.png><link rel=publisher href=https://plus.google.com/115106277658014197977><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin=anonymous><link rel=stylesheet href=https://dominhhai.github.io/css/style-fpbzgxsy0kgmdvyrj5ykkg6ratccrk3gocmaqn4xpcjywmv5dteilzucro4f.min.css><link rel=stylesheet crossorigin=anonymous href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-alpha1/katex.min.css integrity=sha384-8QOKbPtTFvh/lMY0qPVbXj9hDh+v8US0pD//FcoYFst2lCIf0BmT58+Heqj0IGyx><link rel=stylesheet href=https://dominhhai.github.io/css/main.css><script async src="https://www.googletagmanager.com/gtag/js?id=UA-105333519-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)};gtag('js',new Date());gtag('config','UA-105333519-1');</script></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=https://dominhhai.github.io/vi/>Hai&#39;s Blog</a></div><a class=header-right-picture href=https://dominhhai.github.io/#about><img class=header-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=90" alt="Ảnh đại diện"></a></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=https://dominhhai.github.io/#about><img class=sidebar-profile-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=110" alt="Ảnh đại diện"></a><h4 class=sidebar-profile-name>Do Minh Hai</h4><h5 class=sidebar-profile-bio>Just a developer<br>Enjoy life as a journey</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/><i class="sidebar-button-icon fa fa-lg fa-home"></i><span class=sidebar-button-desc>Trang chủ</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/categories/><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i><span class=sidebar-button-desc>Danh mục</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/tags/><i class="sidebar-button-icon fa fa-lg fa-tags"></i><span class=sidebar-button-desc>Thẻ thông tin</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/archives/><i class="sidebar-button-icon fa fa-lg fa-archive"></i><span class=sidebar-button-desc>Lưu trữ</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/#about><i class="sidebar-button-icon fa fa-lg fa-address-card"></i><span class=sidebar-button-desc>Thông tin</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/page/why/><i class="sidebar-button-icon fa fa-lg fa-question"></i><span class=sidebar-button-desc>Hỏi ngu</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/dominhhai target=_blank rel=noopener><i class="sidebar-button-icon fa fa-lg fa-github"></i><span class=sidebar-button-desc>GitHub</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://twitter.com/minhhai3b target=_blank rel=noopener><i class="sidebar-button-icon fa fa-lg fa-twitter"></i><span class=sidebar-button-desc>Twitter</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/index.xml><i class="sidebar-button-icon fa fa-lg fa-rss"></i><span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div id=main data-behavior=5 class=hasCoverMetaIn><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class="post-header main-content-wrap text-center"><h1 class=post-title itemprop=headline>[RNN] Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm</h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-10-22T00:00:00Z>22 tháng 10, 2017</time>
<span>mục</span>
<a class=category-link href=https://dominhhai.github.io/vi/categories/h%e1%bb%8dc-m%c3%a1y>Học Máy</a>,
<a class=category-link href=https://dominhhai.github.io/vi/categories/h%e1%bb%8dc-s%c3%a2u>Học Sâu</a>,
<a class=category-link href=https://dominhhai.github.io/vi/categories/rnn>RNN</a></div></div><div class="post-content markdown" itemprop=articleBody><div class=main-content-wrap><blockquote><p>Bài giới thiệu RNN thứ 3 này được dịch lại từ trang <a href=http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/ target=_blank _ rel="noopener noreferrer">blog WILDML</a>.</p></blockquote><p>Trong phần này tôi sẽ giới thiệu tổng quan về BPTT (Backpropagation Through Time) và giải thích sự khác biệt của nó so với các giải thuật lan truyền ngược truyền thống.
Sau đó ta sẽ cùng tìm hiểu vấn đề mất mát đạo hàm (vanishing gradient problem), nó dẫn ta tới việc phát triển của LSTM và GRU - 2 mô hình phổ biến và mạnh mẽ nhất hiện nay trong các bài toán NLP (và cả các lĩnh vực khác).</p><p>Vấn đề mất mát đạo hàm được khám phá bởi <a href=http://people.idsia.ch/~juergen/fundamentaldeeplearningproblem.html target=_blank _ rel="noopener noreferrer">Sepp Hochreiter năm 1991</a>
và đã cuốn hút được sự quan tâm cho lần nữa trong thời gian gần đây khi mà ứng dụng của các kiến trúc sâu ngày một nhiều hơn.</p><p>Đây là bài thứ 3 trong chuỗi bài giới thiệu về RNN:</p><ul><li>1. <a href=https://dominhhai.github.io/vi/2017/10/what-is-rnn/>Giới thiệu RNN</a></li><li>2. <a href=https://dominhhai.github.io/vi/2017/10/implement-rnn-with-python/>Cài đặt RNN với Python và Theano</a></li><li>3. Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm (bài này)</li><li>4. <a href=https://dominhhai.github.io/vi/2017/10/implement-gru-lstm/>Cài đặt GRU/LSTM</a></li></ul><p>Để có thể hiểu được toàn bộ bài viết này, bạn cần có kiến thức về giải tích và cơ bản về giải thuật lan truyền ngược (backpropagation).
Nếu bạn chưa rõ nó thì có thể đọc tại các bài viết
<a href=http://cs231n.github.io/optimization-2/ target=_blank _ rel="noopener noreferrer">này</a>
và <a href=http://colah.github.io/posts/2015-08-Backprop/ target=_blank _ rel="noopener noreferrer">này</a>
và cả <a href=http://neuralnetworksanddeeplearning.com/chap2.html target=_blank _ rel="noopener noreferrer">đây</a> nữa (thứ tự khó dần nhé).</p><h1 id=table-of-contents>Mục lục</h1><nav id=TableOfContents><ul><li><a href=#1-lan-truyền-ngược-liên-hồi-bptt>1. Lan truyền ngược liên hồi - BPTT</a></li><li><a href=#2-vấn-đề-mất-mát-đạo-hàm>2. Vấn đề mất mát đạo hàm</a></li></ul></nav><h1 id=1-lan-truyền-ngược-liên-hồi-bptt>1. Lan truyền ngược liên hồi - BPTT</h1><p>Nhớ lại chút các công thức cơ bản của RNN. Lưu ý rằng các kí hiệu ở đây có thay đổi 1 chút từ $ o $ thành $ \hat{y} $.
Việc thay đổi này nhằm thống nhất với một vài tài liệu tôi sẽ tham chiếu tới.</p><p>$$
\begin{aligned}
s_t &amp;= \tanh(U x_t + W s_{t-1}) \cr
\hat{y_t} &amp;= \mathrm{softmax}(V s_t)
\end{aligned}
$$</p><p>Ta cũng định nghĩa hàm mất mát, hay hàm lỗi dạng cross entropy như sau:</p><p>$$
\begin{aligned}
E_t(y_t, \hat{y_t}) &amp;= -y_t \log{\hat{y_t}} \cr
E(y, \hat{y}) &amp;= \sum_t{E_t(y_t, \hat{y_t})} \cr
\ &amp;= -\sum_t{y_t \log{\hat{y_t}}}
\end{aligned}
$$</p><p>Ở đây, $ y_t $ là từ chính xác ở bước $ t $, còn $ \hat{y_t} $ là từ mà ta dự đoán.
Ta coi mỗi chuỗi đầy đủ (một câu) là một mẫu huấn luyện.
Vì vậy tổng số lỗi chính là tổng của tất cả các lỗi ở mỗi bước (mỗi từ).</p><div class="figure center"><a class=fancybox href=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/10/rnn-bptt1.png data-fancybox-group><img class=fig-img src=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/10/rnn-bptt1.png></a></div><p>Mục tiêu của ta là tính đạo hàm của lỗi với tham số $ U, V, W $ tương ứng và sau đó học các tham số này bằng cách sử dụng SGD.
Tương tự như việc cộng tổng các lỗi, ta cũng sẽ cộng tổng các đạo hàm tại mỗi bước cho mỗi mẫu huấn luyện:
$\displaystyle \frac{\partial{E}}{\partial{W}} = \sum_t{\frac{\partial{E_t}}{\partial{W}}} $.</p><p>Để tính đạo hàm, ta sử dụng <a href=https://en.wikipedia.org/wiki/Chain_rule target=_blank _ rel="noopener noreferrer">quy tắc chuỗi vi phân</a>.
Quy tắc này được áp dụng cho việc truyền ngược lỗi của <a href=http://colah.github.io/posts/2015-08-Backprop/ target=_blank _ rel="noopener noreferrer">giải thuật lan truyền ngược</a>.</p><p>$$
\begin{aligned}
\frac{\partial{E_3}}{\partial{V}} &amp;= \frac{\partial{E_3}}{\partial{\hat{y_3}}} \frac{\partial{\hat{y_3}}}{\partial{V}} \cr
\ &amp;= \frac{\partial{E_3}}{\partial{\hat{y_3}}} \frac{\partial{\hat{y_3}}}{\partial{z_3}} \frac{\partial{z_3}}{\partial{V}} \cr
\ &amp;= (\hat{y_3} - y_3) \otimes s_3
\end{aligned}
$$</p><p>Trong đó, $ z_3 = V s_3 $ và $ \otimes $ là <a href=https://en.wikipedia.org/wiki/Outer_product target=_blank _ rel="noopener noreferrer">phép nhân ngoài của 2 véc-tơ </a>.
Nếu bạn không hiểu phép khai triển trên thì cũng đừng lo lắng gì cả, tôi có bỏ qua 1 vài bước khi khai triển, nếu cần thiết bạn có thể tự tính đạo hàm xem khớp hay không.
Qua phép khai triển trên, tôi chỉ muốn nói 1 điều là $\displaystyle \frac{\partial{E_3}}{\partial{V}} $
chỉ phụ thuộc vào các giá trị ở bước hiện thời: $ \hat{y_3}, y_3, s_3 $ mà thôi.
Nhìn vào công thức đó, ta thấy rằng tính đạo hàm cho $ V $ chỉ đơn giản là phép nhân ma trận.</p><p>Nhưng với $ W $ và $ U $ thì phép tính của ta lại không đơn giản như vậy.</p><p>$$
\frac{\partial{E_3}}{\partial{W}} = \frac{\partial{E_3}}{\partial{\hat{y_3}}} \frac{\partial{\hat{y_3}}}{\partial{s_3}} \frac{\partial{s_3}}{\partial{W}}
$$</p><p>Với $ s_3 = \tanh{U x_t + W s_2} $ phụ thuộc vào $ s_2 $, còn $ s_2 $ lại phụ thuộc vào $ W $ và $ s_1 $,&hellip;
Vì vậy với W, ta không thể nào coi $ s_2 $ là hẳng số để tính toán như với $ V $ được.
Ta tiếp tục áp dụng quy tắc chuỗi xem sao:</p><p>$$
\frac{\partial{E_3}}{\partial{W}} = \frac{\partial{E_3}}{\partial{\hat{y_3}}} \frac{\partial{\hat{y_3}}}{\partial{s_3}} \frac{\partial{s_3}}{\partial{s_k}} \frac{\partial{s_k}}{\partial{W}}
$$</p><p>Như vậy, với W ta phải cộng tổng tất cả các đầu ra ở các bước trước để tính được đạo hàm.
Nói cách khác, ta phải truyền ngược đạo hàm từ $ t = 3 $ về tới $ t = 0 $.</p><div class="figure center"><a class=fancybox href=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/10/rnn-bptt-with-gradients.png data-fancybox-group><img class=fig-img src=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/10/rnn-bptt-with-gradients.png></a></div><p>Cách làm này cũng giống hệt như giải thuật truyền ngược chuẩn trong mạng nơ-ron truyền thống.
Điểm khác ở đây là ta cộng tổng các đạo hàm của W tại mỗi bước thời gian.
Trong mạng nơ-ron truyền thống, ta không chia sẻ các tham số cho các tầng mạng,
nên ta không cần phải cộng tổng đạo hàm lại với nhau.
Cũng tương tự như với lan truyền ngược truyền thống, ta có thể định nghĩa véc-tơ delta khi lan truyền ngược lại:
$\displaystyle \delta_x^{(3)} = \frac{\partial{E_3}}{\partial{z_2}} = \frac{\partial{E_3}}{\partial{s_3}} \frac{\partial{s_3}}{\partial{s_2}} \frac{\partial{s_2}}{\partial{z_2}} $ với $ z_2 = U x_2 + W s_1 $.
Các công thức tính toán tiếp theo hoàn toàn có thể dạng dụng tương tự.</p><p>Dưới đây là mà nguồn thực hiện BPTT:</p><figure class="highlight python"><figcaption><span>bptt.py</span></figcaption><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br></pre></td><td class=code><pre class="python code-highlight">def bptt(self, x, y):
    T = len(y)
    # Perform forward propagation
    o, s = self.forward_propagation(x)
    # We accumulate the gradients in these variables
    dLdU = np.zeros(self.U.shape)
    dLdV = np.zeros(self.V.shape)
    dLdW = np.zeros(self.W.shape)
    delta_o = o
    delta_o[np.arange(len(y)), y] -= 1.
    # For each output backwards...
    for t in np.arange(T)[::-1]:
        dLdV &#43;= np.outer(delta_o[t], s[t].T)
        # Initial delta calculation: dL/dz
        delta_t = self.V.T.dot(delta_o[t]) * (1 - (s[t] ** 2))
        # Backpropagation through time (for at most self.bptt_truncate steps)
        for bptt_step in np.arange(max(0, t-self.bptt_truncate), t&#43;1)[::-1]:
            # print &#34;Backpropagation step t=%d bptt step=%d &#34; % (t, bptt_step)
            # Add to gradients at each previous step
            dLdW &#43;= np.outer(delta_t, s[bptt_step-1])              
            dLdU[:,x[bptt_step]] &#43;= delta_t
            # Update delta for next step dL/dz at t-1
            delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step-1] ** 2)
    return [dLdU, dLdV, dLdW]</pre></td></tr></tbody></table></figure><p>Nhìn vào đây, ta có thể biết được phần nào mạng RNN chuẩn khó để huấn luyện,
vì các chuỗi (câu) có thể khá dài đến tận 20 từ thậm chí nhiều hơn thế nên
ta cần phải truyền ngược lại thông qua rất nhiều tầng mạng.
Trong thực tế, người ta sẽ bỏ qua một vài bước truyền ở một số bước.</p><h1 id=2-vấn-đề-mất-mát-đạo-hàm>2. Vấn đề mất mát đạo hàm</h1><p>Với các câu dài RNN không thể liên kết được các từ ở cách xa nhau nên việc học các câu dài sẽ bị thất bại. Vậy nguyên nhân là gì, ta cùng bắt đầu tìm hiểu từ công thức tính đạo hàm:</p><p>$$
\frac{\partial{E_3}}{\partial{W}} = \sum_{k=0}^3{
\frac{\partial{E_3}}{\partial{\hat{y_3}}}
\frac{\partial{\hat{y_3}}}{\partial{s_3}}
\frac{\partial{s_3}}{\partial{s_k}}
\frac{\partial{s_k}}{\partial{W}}
}
$$</p><p>Ở đây, $\displaystyle \frac{s_3}{s_k} $ cũng tuân theo quy tắc chuỗi đạo hàm.
Ví dụ: $\displaystyle \frac{s_3}{s_1} = \frac{s_3}{s_2} \frac{s_2}{s_1} $.
Nếu bạn để ý thì sẽ thấy các thành phần ở công thức trên đều là véc-tơ vì phép lấy đạo hàm cho véc-tơ cũng là véc-tơ, nên kết quả thu được sẽ là một ma trận
(<a href=https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant target=_blank _ rel="noopener noreferrer">ma trận Jacobi</a>),
trong đó các phần tử tương ứng được tính theo phép toán <a href=https://en.wikipedia.org/wiki/Pointwise target=_blank _ rel="noopener noreferrer">pointwise</a> với đạo hàm tương ứng.
Ta có thể viết lại công thức trên như sau:</p><p>$$
\frac{\partial{E_3}}{\partial{W}} = \sum_{k=0}^3{
\frac{\partial{E_3}}{\partial{\hat{y_3}}}
\frac{\partial{\hat{y_3}}}{\partial{s_3}}
\Bigg(
\prod_{j=k+1}^3{
\frac{\partial{s_j}}{\partial{s_{j-1}}}
}
\Bigg)
\frac{\partial{s_k}}{\partial{W}}
}
$$</p><p>Tôi không chứng minh ở đây (bạn có thể xem ở <a href=http://www.jmlr.org/proceedings/papers/v28/pascanu13.pdf target=_blank _ rel="noopener noreferrer">đây</a>),
nhưng phép tính trên cho ta một norm bậc 2.
Bạn có thể coi nó là một giá trị tuyệt đối có biên trên là 1 của ma trận Jacobi ở trên.
Vì hàm kích hoạt ($ \tanh $ hay $ sigmoid $) của ta sẽ cho kết quả đầu ra nằm trong đoạn $ [-1, 1] $
nên đạo hàm của nó sẽ bị đóng trong khoảng $ [0, 1] $ (với $ sigmoid $ thì giá trị sẽ là $ [0, 0.25] $).</p><div class="figure center"><a class=fancybox href=https://nn.readthedocs.org/en/rtd/image/tanh.png title="tanh and derivative. Source: http://nn.readthedocs.org/en/rtd/transfer/" data-fancybox-group><img class=fig-img src=https://nn.readthedocs.org/en/rtd/image/tanh.png alt="tanh and derivative. Source: http://nn.readthedocs.org/en/rtd/transfer/"></a>
<span class=caption>tanh and derivative. Source: http://nn.readthedocs.org/en/rtd/transfer/</span></div><p>Nhìn vào hình trên, bạn có thể cả hàm $ \tanh $ lẫn $ sigmoid $ sẽ có đạo hàm bằng $ 0 $ tại 2 đầu.
Mà khi đạo hàm bằng 0 thì nút mạng tương ứng tại đó sẽ bị bão hòa. Lúc đó các nút phía trước cũng sẽ bị bão hoà theo.
Nên với các giá trị nhỏ trong ma trận, khi ta thực hiện phép nhân ma trận sẽ đạo hàm tương ứng sẽ bùng nổi rất nhanh, thậm chí nó sẽ bị triệt tiêu chỉ sau vài bước nhân.
Như vậy, các bước ở xa sẽ không còn tác dụng với nút hiện tại nữa, làm cho RNN không thể học được các phụ thuộc xa.
Vấn đề này không chỉ xảy ra với mạng RNN mà ngay cả mạng nơ-ron chuẩn khá sâu cũng có hiện tượng này.
Như bạn đã biết RNN cũng là một mạng chuẩn sâu, với số tầng mạng bằng với số từ đầu vào của một chuỗi, nên hiện tượng này có thể thấy ngay ở RNN.</p><p>Với cách nhìn như trên ta có thể suy luận thêm <em>vấn đề bùng nổ đạo hàm</em> của RNN nữa.
Tùy thuộc vào hàm kích hoạt và tham số của mạng, vấn đề bùng nổ đạo hàm có thể xảy ra khi các giá trị của ma trận là lớn.
Tuy nhiên, người ta thường nói về vấn đề <em>mất mát đạo hàm</em> nhiều hơn là <em>bùng nổ đạo hàm</em>,
vì 2 lý do sau. Thứ nhất, bùng nổ đạo hàm có thể theo dõi được
vì khi đạo hàm bị bùng nổ thì ta sẽ thu được kết quả là một giá trị phi số <em>NaN</em> làm cho chương trình của ta bị dừng hoạt động.
Lý do thứ 2 là bùng nổ đạo hàm có thể ngăn chặn được khi ta đặt một ngưỡng giá trị trên cho đạo hàm như trong <a href=http://www.jmlr.org/proceedings/papers/v28/pascanu13.pdf target=_blank _ rel="noopener noreferrer">bài viết này</a>.
Còn việc mất mát đạo hàm lại không theo dõi được mà cũng không biết làm sao để xử lý nó cho hợp lý.</p><p>May mắn là giờ đã có nhiều nghiên cứu chỉ ra các cách giải quyết vấn đề này.
Ví dụ như việc khởi tạo tham số $ W $ hợp lý sẽ giúp giảm được hiệu ứng mất mát đạo hàm.
Một phương pháp được ưu chuộng hơn là thay vì sử dụng $ \tanh $ và $ sigmoid $ cho hàm kích hoạt thì ta sử dụng $ ReLU $.
Đạo hàm ReLU sẽ là một số hoặc là 0 hoặc là 1, nên có ta có thể kiểm soát được vấn đề mất mát đạo hàm.
Một phương pháp phổ biến hơn cả là sử dụng kiến trúc nhớ dài-ngắn hạn (LSTM - Long Short-Term Memory) hoặc Gated Recurrent Unit (GRU).
LSTM được <a href=http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf target=_blank _ rel="noopener noreferrer">đề xuất vào năm 1997</a>
và có lẽ giờ nó là phương pháp phổ biến nhất trong lĩnh vực NLP.
Còn GRU mới được <a href=http://arxiv.org/pdf/1406.1078v3.pdf target=_blank _ rel="noopener noreferrer">giới thiệu vào năm 2014</a>,
nó là một phiên bản đơn giản hoá của LSTM.
Cả 2 kiến trúc RNN đó được thiết kế để tránh vấn đề mất mát đạo hàm và hiệu quả cho việc học các phụ thuộc xa.
Giờ tôi sẽ dừng bài viết tại đây để dành phần giới thiệu 2 kiến trúc đó ở bài viết sau.</p></div></div><div id=post-footer class="post-footer main-content-wrap"><div class=post-footer-tags><span class="text-color-light text-small">THẺ ĐÁNH DẤU</span><br><a class="tag tag--primary tag--small" href=https://dominhhai.github.io/vi/tags/rnn/>RNN</a></div><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/implement-gru-lstm/ data-tooltip="[RNN] Cài đặt GRU/LSTM"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml">Tiếp</span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/implement-rnn-with-python/ data-tooltip="[RNN] Cài đặt RNN với Python và Theano"><span class="hide-xs hide-sm text-small icon-mr">Trước</span>
<i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-twitter"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-google-plus"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#disqus_thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#table-of-contents><i class="fa fa-list"></i></a></li></ul></div><div id=disqus_thread><noscript>Please enable JavaScript to view the <a href=//disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div></article><footer id=footer class=main-content-wrap><div id=helpinfo><div id=author><label id=home>Hai's Blog</label><div class=language><label for=language>Other Languages:</label>
<select id=language>
<option title="Tiếng Việt" value=vi selected>Tiếng Việt (vi)</option>
<option title=English value=en-us>English (en-us)</option>
<option title=日本語 value=ja>日本語 (ja)</option></select></div></div><div id=topic><label>Chủ đề</label><ul><li><a href=https://dominhhai.github.io/vi/categories/l%E1%BA%ADp-tr%C3%ACnh/>Lập Trình</a></li><li><a href=https://dominhhai.github.io/vi/categories/h%E1%BB%8Dc-m%C3%A1y/>Học Máy</a></li><li><a href=https://dominhhai.github.io/vi/categories/to%C3%A1n/>Toán</a></li><li><a href=https://dominhhai.github.io/vi/categories/x%C3%A1c-su%E1%BA%A5t/>Xác Suất</a></li><li><a href=https://dominhhai.github.io/vi/categories/s%C3%A1ch/>Sách</a></li></ul></div><div id=contact><label>Liên hệ</label><ul><li><a href=https://github.com/dominhhai/dominhhai.github.io/issues/new target=_blank><i class="fa fa-lg fa-inbox"></i>Gửi tin nhắn</a></li><li id=follow><a href=https://github.com/dominhhai target=_blank><i class="sidebar-button-icon fa fa-lg fa-github"></i></a><a href=https://twitter.com/minhhai3b target=_blank><i class="sidebar-button-icon fa fa-lg fa-twitter"></i></a></li></ul></div></div><div id=contentinfo><span class=copyrights>&copy; 2017 <a href=https://github.com/dominhhai>Do Minh Hai</a>. All Rights Reserved</span></div></footer></div><div id=bottom-bar class=post-bottom-bar data-behavior=5><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/implement-gru-lstm/ data-tooltip="[RNN] Cài đặt GRU/LSTM"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml">Tiếp</span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/implement-rnn-with-python/ data-tooltip="[RNN] Cài đặt RNN với Python và Theano"><span class="hide-xs hide-sm text-small icon-mr">Trước</span>
<i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-twitter"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-google-plus"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#disqus_thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#table-of-contents><i class="fa fa-list"></i></a></li></ul></div></div><div id=share-options-bar class=share-options-bar data-behavior=5><i id=btn-close-shareoptions class="fa fa-close"></i><ul class=share-options><li class=share-option><a class=share-option-btn target=new href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2017%2F10%2Funderstand-rnn-bptt%2F"><i class="fa fa-facebook-official"></i><span>Chia sẻ với Facebook</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2017%2F10%2Funderstand-rnn-bptt%2F"><i class="fa fa-twitter"></i><span>Chia sẻ với Twitter</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://plus.google.com/share?url=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2017%2F10%2Funderstand-rnn-bptt%2F"><i class="fa fa-google-plus"></i><span>Chia sẻ với Google&#43;</span></a></li></ul></div><div id=share-options-mask class=share-options-mask></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-remove"></i></div><img id=about-card-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=110" alt="Ảnh đại diện"><h4 id=about-card-name>Do Minh Hai</h4><div id=about-card-bio>Just a developer<br>Enjoy life as a journey</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>Freelancer</div><div id=about-card-location><i class="fa fa-map-marker"></i><br>Japan</div></div></div><div id=algolia-search-modal class=modal-container><div class=modal><div class=modal-header><span class=close-button><i class="fa fa-close"></i></span><a href=https://algolia.com target=_blank rel=noopener class="searchby-algolia text-color-light link-unstyled"><span class="searchby-algolia-text text-color-light text-small">by</span>
<img class=searchby-algolia-logo src=https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg></a>
<i class="search-icon fa fa-search"></i><form id=algolia-search-form><input id=algolia-search-input name=search class="form-control input--large search-input" placeholder="Tìm kiếm"></form></div><div class=modal-body><div class="no-result text-color-light text-center">không tìm thấy kết quả</div><div class=results><div class=media><div class=media-body><a class=link-unstyled href=https://dominhhai.github.io/vi/2017/12/ml-prml/><h3 class=media-heading>Pattern Recognition and Machine Learning</h3></a><span class=media-meta><span class="media-date text-small">Dec 12, 2017</span></span><div class="media-content hide-xs font-merryweather"><p>Được coi là sách giáo khoa cho những người làm học máy, cuốn sách này viết về các giải thuật và lý thuyết xây dựng các giải thuật nhận dạng mẫu và học máy. Tuy nhiên lúc mới đọc thì thấy khá khó nhằn nên tôi đã tìm hiểu độ khó các phần đề biết đường mà đọc.</p></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=https://dominhhai.github.io/vi/2017/12/ml-intro/><h3 class=media-heading>[ML] Học máy là gì?</h3></a><span class=media-meta><span class="media-date text-small">Dec 12, 2017</span></span><div class="media-content hide-xs font-merryweather"><p>Thời gian gần đây AI nổi lên mạnh mẽ xâm nhập vào rất nhiều lĩnh vực trong cuộc sống như tự động dịch thuật, nhận dạng giọng nói, điều khiển tự động, v.v. Nó giờ được coi là xu hướng công nghệ thế giới và nhiều người cho rằng đó là cuộc cách mạng công nghiệp lần thứ 4.</p></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=https://dominhhai.github.io/vi/2017/11/seiko-no-yotei/><h3 class=media-heading>Điểm cốt lõi để thành công</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2017</span></span><div class="media-content hide-xs font-merryweather">Cuốn sách tổng hợp nội dung của một số buổi nói chuyện của ông Inamori Kazuo về kinh doanh, làm việc, nhân sinh. Vẫn phong cách quen thuộc về cách nhìn cuộc sống, cách suy nghĩ, cách hành động như trong các cuốn sách khác mà ông đã viết, nhưng trong cuốn này đặc biệt ở chỗ tổng hợp được nhiều nội dung khá cô động mà vẫn không thiếu sót nội dung.</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=https://dominhhai.github.io/vi/2017/11/vbnet-oracle-version/><h3 class=media-heading>[.NET] Sài nhiều phiên bản Oracle khi thực thi</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2017</span></span><div class="media-content hide-xs font-merryweather"><p>Thông thường khi ta build ứng dụng thì phiên bản Oracle DB ở môi trường phát triển và môi trường thực thi là giống nhau nên không xảy ra vấn đề gì cả. Nhưng nếu ở môi trường phát triển và thực thi khác nhau thì sao?</p></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=https://dominhhai.github.io/vi/2017/11/what-is-http2/><h3 class=media-heading>[Web] HTTP2 là gì?</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2017</span></span><div class="media-content hide-xs font-merryweather"><p>Nhân tiện bản <code>Node v9x</code> mới ra cho phép ta có thể sử dụng ngay API thử nghiệm <code>HTTP/2</code> nên cũng tò mò tìm hiểu đôi chút xem kiến trúc, đặc điểm và cách sử dụng thế nào.
Sau 2 năm ra chính thức ra lò, phiên bản tiếp theo của <code>HTTP</code> này dần được nhiều máy chủ Web lẫn trình duyệt hỗ trợ bởi tính vượt trội của nó so với phiên bản <code>HTTP/1.1</code>.</p></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=https://dominhhai.github.io/vi/2017/11/about-git/><h3 class=media-heading>[Git] Mô tả về GIT của Linus Torvalds</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2017</span></span><div class="media-content hide-xs font-merryweather"><p>Đây là mô tả về GIT mà chủ nhân của nó - ông Linus Torvalds đã viết khi công khai mã nguồn. Cụ thể bài này được copy lại từ <a href=https://github.com/git/git/tree/e83c5163316f89bfbde7d9ab23ca2e25604af290 target=_blank _ rel="noopener noreferrer">Github</a>.</p></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=https://dominhhai.github.io/vi/2017/10/change-filename-bat/><h3 class=media-heading>[Windows] Đổi tên file với .bat file</h3></a><span class=media-meta><span class="media-date text-small">Oct 10, 2017</span></span><div class="media-content hide-xs font-merryweather">Gần đây Gmail không cho phép gửi các file có đuôi là mã nguồn ngôn ngữ lập trình như .js, .vb chẳng hạn. Ngay cả việc đổi đuôi của các file nén cũng không có hiệu quả như trước, nên buộc phải tìm cách đổi toàn bộ đuôi 1 phát.
Bài viết này sẽ nói về cách thay đổi toàn bộ đuôi file bằng .bat file của Windows, tuy nhiên hoàn toàn có thể sử dụng để làm những chuyện khác với các file này như đổi tên chẳng hạn.</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=https://dominhhai.github.io/vi/2017/10/implement-gru-lstm/><h3 class=media-heading>[RNN] Cài đặt GRU/LSTM</h3></a><span class=media-meta><span class="media-date text-small">Oct 10, 2017</span></span><div class="media-content hide-xs font-merryweather"><blockquote><p>Bài giới thiệu RNN cuối cùng này được dịch lại từ trang <a href=http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/ target=_blank _ rel="noopener noreferrer">blog WILDML</a>.</p></blockquote><p>Trong phần này ta sẽ tìm hiểu về LSTM (Long Short-Term Memory) và GRU (Gated Recurrent Units).
LSTM lần đầu được giới thiệu vào năm 1997 bởi <a href=https://github.com/dzitkowskik/StockPredictionRNN/blob/master/docs/Hochreiter97_lstm.pdf target=_blank _ rel="noopener noreferrer">Sepp Hochreiter và Jürgen Schmidhuber</a>.
Nó giờ hiện diện trên hầu hết các mô hình có sử dụng học sâu cho NPL.
Còn GRU mới được đề xuất vào năm 2014 là một phiên bản đơn giản hơn của LSTM nhưng vẫn giữ được các tính chất của LSTM.</p></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/><h3 class=media-heading>[RNN] Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm</h3></a><span class=media-meta><span class="media-date text-small">Oct 10, 2017</span></span><div class="media-content hide-xs font-merryweather"><blockquote><p>Bài giới thiệu RNN thứ 3 này được dịch lại từ trang <a href=http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/ target=_blank _ rel="noopener noreferrer">blog WILDML</a>.</p></blockquote><p>Trong phần này tôi sẽ giới thiệu tổng quan về BPTT (Backpropagation Through Time) và giải thích sự khác biệt của nó so với các giải thuật lan truyền ngược truyền thống.
Sau đó ta sẽ cùng tìm hiểu vấn đề mất mát đạo hàm (vanishing gradient problem), nó dẫn ta tới việc phát triển của LSTM và GRU - 2 mô hình phổ biến và mạnh mẽ nhất hiện nay trong các bài toán NLP (và cả các lĩnh vực khác).</p></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=https://dominhhai.github.io/vi/2017/10/implement-rnn-with-python/><h3 class=media-heading>[RNN] Cài đặt RNN với Python và Theano</h3></a><span class=media-meta><span class="media-date text-small">Oct 10, 2017</span></span><div class="media-content hide-xs font-merryweather"><blockquote><p>Bài giới thiệu RNN thứ 2 này được dịch lại từ trang <a href=http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/ target=_blank _ rel="noopener noreferrer">blog WILDML</a>.</p></blockquote><p>Trong phần này chúng ta sẽ cài đặt một mạng nơ-ron hồi quy từ đầu sử dụng Python
và tối ưu với <a href=http://deeplearning.net/software/theano/ target=_blank _ rel="noopener noreferrer">Theano</a> - một thư viện tính toán trên GPU.
Tôi sẽ chỉ đề cập các thành phần quan trọng để giúp bạn có thể hiểu được RNN,
còn toàn bộ mã nguồn bạn có thể xem trên <a href=https://github.com/dennybritz/rnn-tutorial-rnnlm target=_blank _ rel="noopener noreferrer">Github</a>.</p></div></div><div style=clear:both></div><hr></div></div></div><div class=modal-footer><p class="results-count text-medium" data-message-zero="không tìm thấy kết quả" data-message-one="tìm thấy 1 kết quả" data-message-other="tìm thấy {n} kết quả">52 posts found</p></div></div></div><div id=cover style=background-image:url(https://dominhhai.github.io/images/cover-v1.2.0.jpg)></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js integrity="sha256-IFHWFEbU2/+wNycDECKgjIRSirRNIDp2acEB5fvdVRU=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js integrity="sha256-+mpyNVJsNt4rVXCw0F+pAOiB3YxmHgrbJsx4ecPuUaI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js integrity="sha256-vMxgR/7FtLovVA+IPrR7+xTgIgARH7y9VZQnmmi0HDI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js integrity="sha256-N0qFUh7/9vLvia87dDndewmsgsyYoNkdA212tPc+2NI=" crossorigin=anonymous></script><script src=https://dominhhai.github.io/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js></script><script crossorigin=anonymous integrity=sha384-GR8SEkOO1rBN/jnOcQDFcFmwXAevSLx7/Io9Ps1rkxWp983ZIuUGfxivlF/5f5eJ src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-alpha1/katex.min.js></script><script crossorigin=anonymous integrity=sha384-cXpztMJlr2xFXyDSIfRWYSMVCXZ9HeGXvzyKTYrn03rsMAlOtIQVzjty5ULbaP8L src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-alpha1/contrib/auto-render.min.js></script><script src=https://dominhhai.github.io/js/main.js></script><script>$(document).ready(function(){hljs.configure({classPrefix:'',useBR:false});$('pre.code-highlight, pre > code').each(function(i,block){if(!$(this).hasClass('codeblock')){$(this).addClass('codeblock');}
hljs.highlightBlock(block);});});</script><script>var disqus_config=function(){this.page.url='https:\/\/dominhhai.github.io\/vi\/2017\/10\/understand-rnn-bptt\/';this.page.identifier='\/vi\/2017\/10\/understand-rnn-bptt\/'};(function(){if(window.location.hostname=="localhost"){return;}
var d=document,s=d.createElement('script');var disqus_shortname='tranquilpeak';s.src='//'+disqus_shortname+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><script>if(typeof fnMain==='function'){fnMain();}</script></body></html>