---
title: "[ML] Tối ưu hàm lỗi với Gradient Descent"
slug: ml-gd
date: 2017-12-22T08:45:04+09:00
categories:
- Học Máy
- ML
tags:
- Học Máy
keywords:
- Học Máy
- Machine Learning
autoThumbnailImage: true
thumbnailImagePosition: left
thumbnailImage: https://res.cloudinary.com/dominhhai/image/upload/dl/logo.png
metaAlignment: center
draft: true
---
Mặc dù sử dụng công thức chuẩn để tìm tham số là có thể thực hiện được, nhưng với tập dữ liệu lớn nhiều chiều trong thực tế thì với máy tính lại không thể thực hiện được do các ràng buộc của bộ nhớ cũng như khả năng tính toán. Chưa kể với nhiều bài toán việc giải được đạo hàm để tìm ra công thức chuẩn là rất khó khăn. Nên trong thực tế giải thuật thay thế là **Gradient Descent** thường được sử dụng.
<!--more-->

Chính vì vậy tôi viết bài này để hiểu rõ hơn về phương pháp tối ưu bằng giải thuật **Gradient Descent** cũng như các biến thể và tối ưu cho giải thuật này. Để cho thuận tiện từ giờ trở đi tôi sẽ viết tắt Gradient Descent là *GD*.

<!--toc-->
# 1. Gradient Descent là gì
Như trong bài [đạo hàm của hàm nhiều biến](/vi/2017/10/multi-var-func/#4-gradient-v%C3%A0-%C4%91%E1%BA%A1o-h%C3%A0m-c%C3%B3-h%C6%B0%E1%BB%9Bng) đã giải thích về gradient và sự biến thiên của hàm số thì hàm số sẽ tăng nhanh nhất theo hướng của gradient (*gradient ascent*) và giảm nhanh nhất theo hướng ngược của gradient (*gradient descent*).

Như vậy một cách trực quan ta có thể nhận xét rằng nếu ta cứ đi ngược hướng đạo hàm mãi thì ta sẽ tới được điểm cực tiểu của hàm số. Nếu bạn cần ví dụ minh họa trực quan thì tôi nghĩ nên xem <a href="https://machinelearningcoban.com/2017/01/12/gradientdescent/" target="_blank"_ rel="noopener noreferrer">bài viết này</a> của anh Tiệp. Theo như tôi thấy thì bài viết của anh ấy rất rõ ràng và đẩy đủ, nên tôi sẽ không phí công viết lại ở đây nữa mà sẽ tập trung vào khai triển cho lập trình.

Giả sử ta cần tìm tham số $\theta\in\mathbb{R}^n$ để tối thiểu hoá hàm lỗi $J(\theta)$. Lúc này giải thuật *GD* được thực hiện bằng cách cập nhập dần các tham số $\theta$ ngược với hướng của gradient $\nabla_\theta J(\theta)$ tại điểm hiện tại cho tới khi nó hội tụ về điểm nhỏ nhất. Tại mỗi bước cập nhập, ta sẽ dịch tham số bằng một lượng $\eta\nabla\_\theta J(\theta)$ với **độ học** (*learning rate*) $\eta>0$ thể hiện cho việc dịch chuyển nhiều tới đâu:
$$\theta^{(k+1)}=\theta^{(k)}-\eta\nabla\_\theta J(\theta^{(k)})$$

$\theta^{(k)}$ ở đây kí hiệu cho tham số tại bước cập nhập lần $k$ khi thực hiện giải thuật *GD*.

Ví dụ, ta có hàm $J(\theta) = \theta_0^2+sin(\theta_1)$. Gradient (ma trận Jacobi) lúc này sẽ là:
$$
\nabla\_\theta J(\theta)=
\begin{bmatrix}
\dfrac{\partial}{\partial\theta_0}J\\cr
\dfrac{\partial}{\partial\theta_1}J
\end{bmatrix}=
\begin{bmatrix}
2\theta_0\\cr
\cos(\theta_1)
\end{bmatrix}
$$

Tại bước bất kì các tham số được cập nhập như sau:
$$
\begin{cases}
\theta_0=\theta_0-\eta2\theta_0 \\cr
\theta_1=\theta_1-\eta\cos(\theta_1)
\end{cases}
$$

Lưu ý rằng ta phải cập nhập đồng thời tham số sau khi tính đạo hàm chứ không được đồng thời vừa tính đạo hàm vừa cập nhập tham số. Ví dụ với `Python`:
{{< codeblock "gradient_descent.py" "python">}}
'''
Evaluate Gradient for J = theta_0^2 + sin(theta_1)
'''
def eval_grad(theta):
  # init gradient
  grad = np.empty_like(theta)
  # eval gradient
  grad[0] = 2 * theta[0]
  grad[1] = np.cos(theta[1])
  return grad

# run 1000 times
NUM_INTERS = 1000
# learning rate
ETA = 0.01

# init theta
theta = np.zeros(2)

# run GD
for (i in range(NUM_INTERS)):
  grad = eval_grad(theta)
  theta -= ETA * grad
{{< /codeblock >}}

# 2. Ứng dụng cho hồi quy tuyến tính
Với bài toán hồi quy tuyến tính ta có công thức tính của hàm lỗi như sau:
$$J(\theta)=\frac{1}{2m}\sum\_{i=1}^m(\theta^{\intercal}\phi(\mathbf{x}_i)-y_i)^2$$
Lúc này ta có gradient:
$$\nabla\_\theta J(\theta)=\frac{1}{m}(\theta^{\intercal}\Phi-y)\Phi$$

Trong đó $\Phi$ là [ma trận mẫu](/vi/2017/12/ml-linear-regression/#5-k%E1%BA%BFt-lu%E1%BA%ADn):
$$\Phi=
\begin{bmatrix}
\phi_0(\mathbf{x}_1)&\phi_1(\mathbf{x}_1)&...&\phi\_{n-1}(\mathbf{x}_1)\\cr
\phi_0(\mathbf{x}_2)&\phi_1(\mathbf{x}_2)&...&\phi\_{n-1}(\mathbf{x}_2)\\cr
\vdots&\vdots&\ddots&\vdots\\cr
\phi_0(\mathbf{x}_m)&\phi_1(\mathbf{x}_m)&...&\phi\_{n-1}(\mathbf{x}_m)
\end{bmatrix}
$$

Như vậy tại mỗi bước tham số được cập nhập:
$$
\theta=\theta-\eta\frac{1}{m}(\theta^{\intercal}\Phi-y)\Phi
$$

Code với `Python`:
{{< codeblock "gradient_descent.py" "python" "https://github.com/dominhhai/mldl/blob/master/coursera-ml/ex1.ipynb">}}
def gradient_descent(X, y, theta, eta, num_inters):
    # number of training examples
    m = y.size

    for i in range(num_inters):
        delta = np.dot(np.dot(X, theta) - y, X) / m
        theta -= eta * delta

    return theta
{{< /codeblock >}}

Mã nguồn mẫu đầy đủ bạn có thể xem <a href="https://github.com/dominhhai/mldl/blob/master/coursera-ml/ex1.ipynb" target="_blank"_ rel="noopener noreferrer">tại đây</a> nhé.

# 3. Các biến thể
Dạng cài đặt như ở ví dụ trên được gọi là GD thuần (*Vanilla GD*) hay GD toàn phần (*Batch GD*).

# 4. Tối ưu Gradient Descent
# 5. Kết luận
