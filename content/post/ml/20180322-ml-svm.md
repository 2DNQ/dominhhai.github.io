---
title: "[ML] Support Vector Machine - SVM"
slug: ml-svm
date: 2018-03-22T10:20:14+09:00
categories:
- Học Máy
- ML
tags:
- Học Máy
keywords:
- Học Máy
- Machine Learning
- SVM
- kernel method
autoThumbnailImage: true
thumbnailImagePosition: left
thumbnailImage: https://res.cloudinary.com/dominhhai/image/upload/dl/logo.png
metaAlignment: center
draft: true
---
Support Vector Machine - **SVM** là một phương pháp học có giám sát trong các mô hình nhận dạng mẫu. Nó không chỉ hoạt động tốt với các dữ liệu được phân tách tuyến tính mà còn tốt với cả dữ liệu phân tách phi tuyến. Với nhiều bài toán, SVM mang lại kết quả tốt như mạng nơ-ron với hiệu quả sử dụng tài nguyên tốt hơn hẳn.
<!--more-->
<!--toc-->

# 1. Phương pháp SVM
Như đã biết, với bài toán phân loại nhị phân tuyến tính ta cần vẽ được mặt phân tách (với không gian 2 chiều thì mặt phẳng này là đường phân tách): $\mathbf{w}^{\intercal}\mathbf{x}+b=0$ để phân biệt được dữ liệu. Khi đó dấu của hàm ước lượng $H=\\{\mathbf{x}	\mapsto\mathrm{sgn}(\mathbf{w}^{\intercal}\mathbf{x}+b)~~~;\mathbf{w}\in\mathbb{R}^N,b\in\mathbb{R}\\}$ sẽ thể hiện được điểm dữ liệu $\mathbf{x}$ nằm ở cụm dữ liệu nào.

{{< image classes="fancybox center" thumbnail-width="100%" src="/images/ml-20180322-svm_1.svg" title="Mặt phân cách dữ liệu" >}}

Nếu để ý thì ta có thể có nhiều mặt phân tách thoả mãn được việc này và đương nhiên là nếu chọn được mặt mà phân tách tốt thì kết quả phân loại của ta sẽ tốt hơn. Một lẽ rất tự nhiên là dường như mặt nằm vừa khít giữa 2 cụm dữ liệu sao cho nằm xa các tập dữ liệu nhất là mặt tốt nhất.

{{< image classes="fancybox center" thumbnail-width="100%" src="/images/ml-20180322-svm_2.svg" title="Max Margin" >}}

**SVM** chính là một biện pháp để thực hiện được phép lấy mặt phẳng như vậy.



# 2. Dữ liệu chồng nhau và phương pháp biên mềm

# 3. Dữ liệu phân tách phi tuyến và phương pháp kernel

# 4. Phân tách nhiều lớp

# 5. Kết luận
